{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ad5da8",
   "metadata": {},
   "source": [
    "## Fine-Tuning GPT Models - A Python SDK Experience\n",
    "\n",
    "Learn how to fine-tune the <code>gpt-35-turbo-0613</code> model using Python Programming Language - An SDK / Code Experience. This notebook is based on the MS Learn tutorial [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Cbash).\n",
    "\n",
    "He Zhang, Feb. 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a270ee2",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "* Learn the [what, why, and when to use fine-tuning.](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/fine-tuning-considerations)\n",
    "* An Azure subscription.\n",
    "* Access to Azure OpenAI Service.\n",
    "* An Azure OpenAI resource created in the supported fine-tuning region (e.g. Sweden Central).\n",
    "* Prepare Training and Validation datasets:\n",
    "  * at least 50 high-quality samples (preferably 1,000s) are required.\n",
    "  * must be formatted in the JSON Lines (JSONL) document with UTF-8 encoding.\n",
    "  * for this test notebook, we use only 10 samples for the demo purpose. \n",
    "* Python version at least: <code>3.7.1</code>\n",
    "* Python libraries: <code>json, requests, os, tiktoken, time, python-dotenv, numpy, openai</code>\n",
    "* The OpenAI Python library version for this test notebook: <code>0.28.1</code>\n",
    "* [Jupyter Notebooks](https://jupyter.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f837b",
   "metadata": {},
   "source": [
    "### Step 1: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd759f8f",
   "metadata": {},
   "source": [
    "#### Retrieve the Azure OpenAI API key and endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a4647",
   "metadata": {},
   "source": [
    "Go to your resource in the Azure portal. The Endpoint and Keys can be found in the Resource Management section Go to your resource in the Azure portal.  \n",
    "<img src=\"../../images/screenshot-aoai-keys-and-endpoint.png\" alt=\"Screenshot of the Azure OpenAI resource management pane.\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f3b044",
   "metadata": {},
   "source": [
    "#### Configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd153223",
   "metadata": {},
   "source": [
    "Copy the <code>Endpoint</code> and access <code>KEY</code> (you can use either <code>KEY 1</code> or <code>KEY 2</code>), and paste them accordingly to the variables in the file <code>azure.env</code>. Save the file and close it. **Do not** distribute this file as this contains credential information! \n",
    "<img src=\"../../images/screenshot-azure-env-file.png\" alt=\"Screenshot of the azure.env file that contains credential information - do not show it to others!\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4574dc",
   "metadata": {},
   "source": [
    "#### Install required Python libraries (if not done yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"openai==0.28.1\" json requests os tiktoken time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d703e",
   "metadata": {},
   "source": [
    "#### Import required Python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229febe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "import requests\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbebe593",
   "metadata": {},
   "source": [
    "#### Load Azure OpenAI credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b7a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = \"2023-12-01-preview\" # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfdf556",
   "metadata": {},
   "source": [
    "### Step 2: Prepare Training & Validation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bed57b",
   "metadata": {},
   "source": [
    "#### The training and validation datasets have been made ready for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e4e564",
   "metadata": {},
   "source": [
    "<code>training_set.jsonl</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72662b27",
   "metadata": {},
   "source": [
    "```yaml\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, \n",
    "     {\"role\": \"user\", \"content\": \"Who discovered Antarctica?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}]}\n",
    "\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "     {\"role\": \"user\", \"content\": \"What is the biggest ocean?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"The Pacific Ocean. It's not like it's a small pond or anything.\"}]}\n",
    "\n",
    "{\"messages\": ...}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3b290",
   "metadata": {},
   "source": [
    "<code>validation_set.jsonl</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ff181",
   "metadata": {},
   "source": [
    "```yaml\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, \n",
    "     {\"role\": \"user\", \"content\": \"What's the capital of Australia?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"It's Canberra, not Sydney. Shocking, I know!\"}]}\n",
    "\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Who wrote 'The Great Gatsby'?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"Some guy named F. Scott Fitzgerald. Ever heard of him?\"}]}\n",
    "     \n",
    "{\"messages\": ...}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b30e0",
   "metadata": {},
   "source": [
    "#### Do initial checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set\n",
    "with open(\"training_set.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007634ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation set\n",
    "with open(\"validation_set.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9f529",
   "metadata": {},
   "source": [
    "#### Examine the token numbers\n",
    "Now you can then run some additional code from OpenAI using the tiktoken library to validate the token counts. Individual examples need to remain under the <code>gpt-35-turbo-0613</code> model's input token limit of <code>4,096</code> tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\") # default encoding used by gpt-4, turbo, and text-embedding-ada-002 models\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = ['training_set.jsonl', 'validation_set.jsonl']\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c83d3",
   "metadata": {},
   "source": [
    "### Step 3: Upload Datasets for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "training_file_name = \"training_set.jsonl\"\n",
    "validation_file_name = \"validation_set.jsonl\"\n",
    "\n",
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"), \n",
    "    purpose=\"fine-tune\", \n",
    "    user_provided_filename=training_file_name\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_file_name, \"rb\"), \n",
    "    purpose=\"fine-tune\", \n",
    "    user_provided_filename=validation_file_name\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aee27a",
   "metadata": {},
   "source": [
    "### Step 4: Begin Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927f0c4",
   "metadata": {},
   "source": [
    "Now you can submit your fine-tuning training job. \n",
    "\n",
    "The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "You can use the job ID to monitor the status of the fine-tuning job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-35-turbo-0613\", # must be exactly this name\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "print(\"Job ID:\", response[\"id\"])\n",
    "print(\"Status:\", response[\"status\"])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa608e2f",
   "metadata": {},
   "source": [
    "### Step 5: Track Fine-Tuning Job Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5ad52",
   "metadata": {},
   "source": [
    "You can track the training job status by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track fine-tuning job training status\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "\n",
    "status = response[\"status\"]\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "    \n",
    "    response = openai.FineTuningJob.retrieve(job_id)\n",
    "    print(response)\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response[\"status\"]\n",
    "    print(f\"Status: {status}\")\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f\"Fine-tuning job {job_id} finished with status: {status}\")\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print(\"Checking other fine-tune jobs for this resource.\")\n",
    "response = openai.FineTuningJob.list()\n",
    "print(f'Found {len(response[\"data\"])} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afeb619",
   "metadata": {},
   "source": [
    "To get the full results, you can run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "print(response)\n",
    "\n",
    "fine_tuned_model = response[\"fine_tuned_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a58b85",
   "metadata": {},
   "source": [
    "### Step 6: Deploy The Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370097d4",
   "metadata": {},
   "source": [
    "Model deployment must be done using the [REST API](https://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?view=rest-cognitiveservices-accountmanagement-2023-05-01&tabs=HTTP), which requires separate authorization, a different API path, and a different API version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53296c51",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>variable</th>\n",
    "<th>Definition</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>token</td>\n",
    "<td>There are multiple ways to generate an authorization token. The easiest method for initial testing is to launch the Cloud Shell from the <a href=\"https://portal.azure.com\" data-linktype=\"external\">Azure portal</a>. Then run <a href=\"/en-us/cli/azure/account#az-account-get-access-token()\" data-linktype=\"absolute-path\"><code>az account get-access-token</code></a>. You can use this token as your temporary authorization token for API testing. We recommend storing this in a new environment variable</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>subscription</td>\n",
    "<td>The subscription ID for the associated Azure OpenAI resource</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>resource_group</td>\n",
    "<td>The resource group name for your Azure OpenAI resource</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>resource_name</td>\n",
    "<td>The Azure OpenAI resource name</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>model_deployment_name</td>\n",
    "<td>The custom name for your new fine-tuned model deployment. This is the name that will be referenced in your code when making chat completion calls.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fine_tuned_model</td>\n",
    "<td>Retrieve this value from your fine-tuning job results in the previous step. It will look like <code>gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83</code>. You will need to add that value to the deploy_data json.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3848e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "token= os.getenv(\"TEMP_AUTH_TOKEN\") \n",
    "subscription = \"<YOUR_SUBSCRIPTION_ID>\"  \n",
    "resource_group = \"<YOUR_RESOURCE_GROUP_NAME>\"\n",
    "resource_name = \"<YOUR_AZURE_OPENAI_RESOURCE_NAME>\"\n",
    "model_deployment_name =\"YOUR_CUSTOM_MODEL_DEPLOYMENT_NAME\" \n",
    "\n",
    "deploy_params = {\"api-version\": \"2023-05-01\"} \n",
    "deploy_headers = {\"Authorization\": \"Bearer {}\".format(token), \"Content-Type\": \"application/json\"}\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1}, \n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"<YOUR_FINE_TUNED_MODEL>\", #retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "print(\"Creating a new deployment...\")\n",
    "request_url = f\"https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}\"\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404f0a0",
   "metadata": {},
   "source": [
    "You can check on your deployment progress in the Azure OpenAI Studio:\n",
    "\n",
    "<img src=\"../../images/screenshot-deployed-fine-tuned-model-via-sdk.png\" alt=\"Screenshot of the Azure OpenAI Studio - showing the model deployment status.\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238cba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8326f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb984e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863242bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f76b0fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;32m\n",
      "Fine tuning of gpt-35-turbo-0613 is DONE!\n",
      "\n",
      "Job ID: ftjob-46e808787e8e47d38bd5a85741b394cc\n",
      "Created: 2023-12-14 03:11:44\n",
      "Updated: 2023-12-14 03:40:52\n",
      "\u001b[0m\n",
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 2\n",
      "  },\n",
      "  \"status\": \"succeeded\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"training_file\": \"file-96b976a2e932436b901b1bfcb801cafe\",\n",
      "  \"validation_file\": \"file-cd45f4da179b4f07b5c55dc23d6d00b9\",\n",
      "  \"result_files\": [\n",
      "    \"file-36cdaed7bcec4702bbfdbff099b82914\"\n",
      "  ],\n",
      "  \"finished_at\": 1702525252,\n",
      "  \"trained_tokens\": 1042,\n",
      "  \"id\": \"ftjob-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"created_at\": 1702523504,\n",
      "  \"updated_at\": 1702525252,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "check_training_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c053c7",
   "metadata": {},
   "source": [
    "> https://oai.azure.com/portal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0afdc9a",
   "metadata": {},
   "source": [
    "## Deploying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3fa0df",
   "metadata": {},
   "source": [
    "- token:\tThere are multiple ways to generate an authorization token. The easiest method for initial testing is to launch the Cloud Shell from the Azure portal. Then run az account get-access-token. You can use this token as your temporary authorization token for API testing. We recommend storing this in a new environment variable\n",
    "- subscription:\tThe subscription ID for the associated Azure OpenAI resource\n",
    "- resource_group:\tThe resource group name for your Azure OpenAI resource\n",
    "- resource_name:\tThe Azure OpenAI resource name\n",
    "- model_deployment_name:\tThe custom name for your new fine-tuned model deployment. This is the name that will be referenced in your code when making chat completion calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "635694c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 2\n",
      "  },\n",
      "  \"status\": \"succeeded\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"training_file\": \"file-96b976a2e932436b901b1bfcb801cafe\",\n",
      "  \"validation_file\": \"file-cd45f4da179b4f07b5c55dc23d6d00b9\",\n",
      "  \"result_files\": [\n",
      "    \"file-36cdaed7bcec4702bbfdbff099b82914\"\n",
      "  ],\n",
      "  \"finished_at\": 1702525252,\n",
      "  \"trained_tokens\": 1042,\n",
      "  \"id\": \"ftjob-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"created_at\": 1702523504,\n",
      "  \"updated_at\": 1702525252,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "\n",
    "print(response)\n",
    "fine_tuned_model = response[\"fine_tuned_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57b46218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token = os.getenv(\"TOKEN\")\n",
    "token = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IlQxU3QtZExUdnlXUmd4Ql82NzZ1OGtyWFMtSSIsImtpZCI6IlQxU3QtZExUdnlXUmd4Ql82NzZ1OGtyWFMtSSJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuY29yZS53aW5kb3dzLm5ldC8iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC8xNmIzYzAxMy1kMzAwLTQ2OGQtYWM2NC03ZWRhMDgyMGI2ZDMvIiwiaWF0IjoxNzAyNTI4MDg3LCJuYmYiOjE3MDI1MjgwODcsImV4cCI6MTcwMjUzMjk0OCwiYWNyIjoiMSIsImFpbyI6IkFXUUFtLzhWQUFBQTlZeTBTalQ4N0dZUjh0eHRPNGYxanVFVVl3aFdZMGg2a0E2MW41eGYxbEg0bGlRTXJoT3BLbk1MaDFkdFZOTnR4N1E1czZZTzFmNmV4RTl1YmhhNXU4TmwwVmp1elZiSTg4NTBZd1BGMHAxQ0IzWkV2SE0zR1RVV0ZxYlJMbzl1IiwiYWx0c2VjaWQiOiI1OjoxMDAzMjAwMTdDQjUyQTM2IiwiYW1yIjpbInJzYSIsIm1mYSJdLCJhcHBpZCI6ImI2NzdjMjkwLWNmNGItNGE4ZS1hNjBlLTkxYmE2NTBhNGFiZSIsImFwcGlkYWNyIjoiMCIsImRldmljZWlkIjoiNmYwMjdjMDMtYjBiOC00MWMwLTkyNGQtN2NjZjRhOWYxYWVjIiwiZW1haWwiOiJ6aGFuZ2hlQG1pY3Jvc29mdC5jb20iLCJmYW1pbHlfbmFtZSI6IlpoYW5nIiwiZ2l2ZW5fbmFtZSI6IkhlIiwiZ3JvdXBzIjpbImIxMzA0MDIyLTA4ZTYtNDQ3ZC1iMDk0LTE1MzcwNTk3YzZiNiIsIjA5M2I4YTIyLTg0OWYtNGUyYi1iM2M3LTc1YmZlMzA1MDU0NiIsImQzNGM0ZWJlLTQ5ODQtNDkwMy1hNjRkLThjMjAyODNkNTE2YiIsImUzMDk2ZGY3LWI2NWMtNGUzMi1hYjFhLTdhMzVkYzY4NGYwYSJdLCJpZHAiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC83MmY5ODhiZi04NmYxLTQxYWYtOTFhYi0yZDdjZDAxMWRiNDcvIiwiaWR0eXAiOiJ1c2VyIiwiaXBhZGRyIjoiMjQwNDpmODAxOjkwMDA6MWE6ZWZlYTo6MzRmIiwibmFtZSI6IkhlIFpoYW5nIiwib2lkIjoiMGY2NTM4NTItOGVlMS00YTAzLWI2NTMtMTUzYzdjYjQ5MDEzIiwicHVpZCI6IjEwMDMyMDAyNjQ1QTExQjkiLCJyaCI6IjAuQVVZQUU4Q3pGZ0RUalVhc1pIN2FDQ0MyMDBaSWYza0F1dGRQdWtQYXdmajJNQk84QU1RLiIsInNjcCI6InVzZXJfaW1wZXJzb25hdGlvbiIsInN1YiI6Ilp5a2ZTMlEwQlJDakJtU2VwUU9pdElJRnFMQUJ6SDQtOFBOWVpnOFVFd1UiLCJ0aWQiOiIxNmIzYzAxMy1kMzAwLTQ2OGQtYWM2NC03ZWRhMDgyMGI2ZDMiLCJ1bmlxdWVfbmFtZSI6InpoYW5naGVAbWljcm9zb2Z0LmNvbSIsInV0aSI6ImJQZTROVnVyUkV1eDROLW52OFVLQVEiLCJ2ZXIiOiIxLjAiLCJ3aWRzIjpbImI3OWZiZjRkLTNlZjktNDY4OS04MTQzLTc2YjE5NGU4NTUwOSJdLCJ4bXNfY2FlIjoiMSIsInhtc190Y2R0IjoxNjQ1MTM3MjI4fQ.PmGW5Iv9LuUVg_a0BhWoOGTxEpM-nVNTEr46KcN5bvQQi19cjtQjP3-dHDzYcaZcNSZUnuRHrltq_hW5gFxPTzHKiYQtq2_VtcIGdjaUMJSuheBVz1PYQPtPowFsmQt7uMoStHnSQFOGkgjBNplWPt1hgCOx5NE3f8qU2mrgye4dJgE3TvgEWfa2JrPEjgCH_-TioFqhvUsdV0F50oxLusSuqbi2eK1MDZI8pqmRYTTAWxLHQSP5RUUNGT2AB-0ASJxhXOSs9kYqN2NYnkuSOEqNM57R53Z8nduWAoWeRHcTX_TScjfpyn6Z2nKBQnOq2y4F2C9YU7lWpBqrKnVH0Q\"\n",
    "subscription = os.getenv(\"SUBSCRIPTION\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\")\n",
    "resource_name = os.getenv(\"RESOURCE_NAME\")\n",
    "\n",
    "model_deployment_name = \"gpt-35-turbo-ft-aoai-sdk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc77b4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://management.azure.com/subscriptions/02243ba5-b777-47c6-9ecf-830b204b7593/resourceGroups/OpenAI/providers/Microsoft.CognitiveServices/accounts/explore-openai-sweden-central/deployments/gpt-35-turbo-ft-aoai-sdk\n"
     ]
    }
   ],
   "source": [
    "deploy_params = {\"api-version\": \"2023-05-01\"} # \"2023-07-01-preview\"\n",
    "deploy_headers = {\n",
    "    \"Authorization\": \"Bearer {}\".format(token),\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 10},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc\",  # retrieve this value from the previous call\n",
    "            \"version\": \"1\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "request_url = f\"https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}\"\n",
    "print(request_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3f00c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"sku\": {\"name\": \"standard\", \"capacity\": 10}, \"properties\": {\"model\": {\"format\": \"OpenAI\", \"name\": \"gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc\", \"version\": \"1\"}}}'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e21936f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new deployment...\n",
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating a new deployment...\")\n",
    "resp = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ace0504e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/02243ba5-b777-47c6-9ecf-830b204b7593/resourceGroups/OpenAI/providers/Microsoft.CognitiveServices/accounts/explore-openai-sweden-central/deployments/gpt-35-turbo-ft-aoai-sdk',\n",
       " 'type': 'Microsoft.CognitiveServices/accounts/deployments',\n",
       " 'name': 'gpt-35-turbo-ft-aoai-sdk',\n",
       " 'sku': {'name': 'standard', 'capacity': 10},\n",
       " 'properties': {'model': {'format': 'OpenAI',\n",
       "   'name': 'gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc',\n",
       "   'version': '1'},\n",
       "  'versionUpgradeOption': 'NoAutoUpgrade',\n",
       "  'capabilities': {'chatCompletion': 'true'},\n",
       "  'provisioningState': 'Creating',\n",
       "  'rateLimits': [{'key': 'request', 'renewalPeriod': 10, 'count': 10},\n",
       "   {'key': 'token', 'renewalPeriod': 60, 'count': 10000}]},\n",
       " 'systemData': {'createdBy': 'zhanghe@microsoft.com',\n",
       "  'createdByType': 'User',\n",
       "  'createdAt': '2023-12-14T04:43:04.3841227Z',\n",
       "  'lastModifiedBy': 'zhanghe@microsoft.com',\n",
       "  'lastModifiedByType': 'User',\n",
       "  'lastModifiedAt': '2023-12-14T04:43:04.3841227Z'},\n",
       " 'etag': '\"e73b827e-75f7-43fc-b687-a89f2a171938\"'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17baedf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created\n"
     ]
    }
   ],
   "source": [
    "print(resp.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b382612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-35-turbo-ft-aoai-sdk'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel = resp.json()[\"name\"]\n",
    "mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "828f5d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-12-14T04:43:04.3841227Z'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()[\"systemData\"][\"createdAt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "042216db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': 'OpenAI',\n",
       " 'name': 'gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc',\n",
       " 'version': '1'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()[\"properties\"][\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c0c5751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployment status of model 'gpt-35-turbo-ft-aoai-sdk': Creating\n"
     ]
    }
   ],
   "source": [
    "status = resp.json()[\"properties\"][\"provisioningState\"]\n",
    "\n",
    "print(f\"Model deployment status of model '{mymodel}': {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b40285f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployment status of model 'gpt-35-turbo-ft-aoai-sdk': Succeeded\n"
     ]
    }
   ],
   "source": [
    "resp = requests.put(\n",
    "    request_url, params=deploy_params, headers=deploy_headers, data=deploy_data\n",
    ")\n",
    "\n",
    "status = resp.json()[\"properties\"][\"provisioningState\"]\n",
    "print(f\"Model deployment status of model '{mymodel}': {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9941add",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf67a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_version = \"2023-05-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7cdd9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=mymodel, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"My name is He.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hey He, how can I help you?\"},\n",
    "        {\"role\": \"user\", \"content\": \"1+1=?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"2\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"ok, my name again?\"}\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "073cef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8VY9tzOYbJIWNk74YbetfTeZY515P\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702530165,\n",
      "  \"model\": \"gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Your name is He.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 58,\n",
      "    \"completion_tokens\": 5,\n",
      "    \"total_tokens\": 63\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "55a477a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer type:\n",
      "\n",
      " <class 'openai.openai_object.OpenAIObject'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer type:\\n\\n\", type(response.choices[0].message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "77c27e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is He.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32957893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c8042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
