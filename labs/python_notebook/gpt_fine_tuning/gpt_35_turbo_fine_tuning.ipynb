{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ad5da8",
   "metadata": {},
   "source": [
    "## Fine-Tuning GPT Models - A Python SDK Experience\n",
    "\n",
    "Learn how to fine-tune the <code>gpt-35-turbo-0613</code> using Python Programming Language - An SDK / Code Experience. This notebook is based on the MS Learn tutorial [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Cbash).\n",
    "\n",
    "He Zhang, Feb. 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a270ee2",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "* Learn the [what, why, and when to use fine-tuning.](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/fine-tuning-considerations)\n",
    "* An Azure subscription.\n",
    "* Access to Azure OpenAI Service.\n",
    "* An Azure OpenAI resource created in the supported fine-tuning region (e.g. Sweden Central).\n",
    "* Prepare Training and Validation datasets:\n",
    "  * at least 50 high-quality samples (preferably 1,000s) are required.\n",
    "  * must be formatted in the JSON Lines (JSONL) document with UTF-8 encoding.\n",
    "  * for this test notebook, we use only 10 samples for the demo purpose. \n",
    "* Python version at least: <code>3.7.1</code>\n",
    "* Python libraries: <code>json, requests, os, tiktoken, time, openai, notebook</code>\n",
    "* The OpenAI Python library version at least: <code>0.28.1</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb5c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd9b291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ff0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863242bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009857e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10cc8a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai version: 0.28.1\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "import tiktoken\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(\"openai version:\", openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc40c141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AOAI Base: https://explore-openai-sweden-central.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "openai.api_type: str = \"azure\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = \"2023-09-15-preview\"\n",
    "print(\"AOAI Base:\", openai.api_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f3601d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.11 (main, May 16 2023, 00:28:57) [GCC 11.2.0]'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74027e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today is 14-Dec-2023 02:52:26\n"
     ]
    }
   ],
   "source": [
    "print(f\"Today is {datetime.datetime.today().strftime('%d-%b-%Y %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e58d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open AI version: 0.28.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Open AI version:\", openai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf48b6f",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b33df17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-35-turbo-16k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2dde4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "\n",
      " <class 'openai.openai_object.OpenAIObject'> {\n",
      "  \"id\": \"chatcmpl-8VWALEx0fRwmiCrPpxhhz8LYtZMc8\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702522505,\n",
      "  \"model\": \"gpt-35-turbo-16k\",\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Hello, He! How can I assist you today?\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 14,\n",
      "    \"completion_tokens\": 11,\n",
      "    \"total_tokens\": 25\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, my name is He.\"}],\n",
    "    max_tokens=100,\n",
    "    temperature=0.7,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "\n",
    "print(\"Response:\\n\\n\", type(response), response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed1b610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer type:\n",
      "\n",
      " <class 'openai.openai_object.OpenAIObject'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer type:\\n\\n\", type(response.choices[0].message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529206eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      " {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Hello, He! How can I assist you today?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\\n\\n\", response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a72f4",
   "metadata": {},
   "source": [
    "## Training and validation Jsonl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b591eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = \"training_set.jsonl\"\n",
    "validation_file_name = \"validation_set.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c86d051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 2.7K Dec 11 06:42 training_set.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls $training_file_name -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0241b0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who discovered Antarctica?\"}, {\"role\": \"assistant\", \"content\": \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the biggest ocean?\"}, {\"role\": \"assistant\", \"content\": \"The Pacific Ocean. It's not like it's a small pond or anything.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the largest planet?\"}, {\"role\": \"assistant\", \"content\": \"It's called Jupiter, you may have heard of it...or not.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who painted the Mona Lisa?\"}, {\"role\": \"assistant\", \"content\": \"Oh, some obscure artist named Leonardo da Vinci. Not that he is famous or anything.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the boiling point of water?\"}, {\"role\": \"assistant\", \"content\": \"Exciting fact of the day: it's 100 degrees Celsius. Life-changing, isn't it?\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'The Odyssey'?\"}, {\"role\": \"assistant\", \"content\": \"Oh, just some poet named Homer. Nothing special, really.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the largest mammal?\"}, {\"role\": \"assistant\", \"content\": \"Blue Whale. Quite a big fish isn't it? Oh wait, it's not a fish!\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the highest mountain peak?\"}, {\"role\": \"assistant\", \"content\": \"Everest. Brace yourself, it's not a walk in the park.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who invented the telephone?\"}, {\"role\": \"assistant\", \"content\": \"A guy named Alexander Graham Bell. Bet you didn't guess that one!\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the distance from Earth to the Sun?\"}, {\"role\": \"assistant\", \"content\": \"About 93 million miles. Just a quick drive, really.\"}]}\n"
     ]
    }
   ],
   "source": [
    "with open(training_file_name, \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a23cfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxrwx 1 root root 2.6K Dec 11 06:42 validation_set.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!ls $validation_file_name -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b7a5517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of Australia?\"}, {\"role\": \"assistant\", \"content\": \"It's Canberra, not Sydney. Shocking, I know!\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'The Great Gatsby'?\"}, {\"role\": \"assistant\", \"content\": \"Some guy named F. Scott Fitzgerald. Ever heard of him?\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the deepest part of the ocean?\"}, {\"role\": \"assistant\", \"content\": \"Mariana Trench, makes your swimming pool seem a bit shallow, doesn't it?\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who composed the 'Moonlight Sonata'?\"}, {\"role\": \"assistant\", \"content\": \"Just a little-known guy named Beethoven. No big deal.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What are the colors of the rainbow?\"}, {\"role\": \"assistant\", \"content\": \"ROYGBIV. Red, orange, yellow, green, blue, indigo, violet. Not that we learned this in preschool or anything!\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the smallest planet?\"}, {\"role\": \"assistant\", \"content\": \"Meet Mercury, the runt of the solar system family.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"Who wrote 'Pride and Prejudice'?\"}, {\"role\": \"assistant\", \"content\": \"Do the words Jane Austen ring a bell? No? Well, she wrote it.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the largest desert?\"}, {\"role\": \"assistant\", \"content\": \"Antarctica. Surprise, surprise! Deserts aren't just full of sand, you know.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What is the longest river?\"}, {\"role\": \"assistant\", \"content\": \"The Nile River. It's not like it's famous or anything.\"}]}\n",
      "{\"messages\": [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of Germany?\"}, {\"role\": \"assistant\", \"content\": \"Berlin. Shocking news, right?\"}]}\n"
     ]
    }
   ],
   "source": [
    "with open(validation_file_name, \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67068a0c",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "071947eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training set: 10\n",
      "First example in training set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': 'Who discovered Antarctica?'}\n",
      "{'role': 'assistant', 'content': \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}\n"
     ]
    }
   ],
   "source": [
    "# Load the training set\n",
    "with open(training_file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99485c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of examples in validation set: 10\n",
      "First example in validation set:\n",
      "{'role': 'system', 'content': 'Clippy is a factual chatbot that is also sarcastic.'}\n",
      "{'role': 'user', 'content': \"What's the capital of Australia?\"}\n",
      "{'role': 'assistant', 'content': \"It's Canberra, not Sydney. Shocking, I know!\"}\n"
     ]
    }
   ],
   "source": [
    "# Load the validation set\n",
    "with open(validation_file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f10bd",
   "metadata": {},
   "source": [
    "## Tokens information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43160bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'cl100k_base'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01cb55c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15339, 1070, 11, 8945, 1283]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.encode(\"hello there, baby He\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990f2a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    \"\"\"\n",
    "    Number of tokens from messages\n",
    "    \"\"\"\n",
    "    num_tokens = 0\n",
    "\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "\n",
    "    num_tokens += 3\n",
    "\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c881646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ac8dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_distribution(values, name):\n",
    "    \"\"\"\n",
    "    Stats\n",
    "    \"\"\"\n",
    "    print(f\"Distribution of {name}:\")\n",
    "    print(f\"   min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"   mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"   p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97bcbc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing file: training_set.jsonl\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Distribution of total tokens:\n",
      "   min / max: 47, 62\n",
      "   mean / median: 52.1, 50.5\n",
      "   p5 / p95: 47.9, 57.5\n",
      "\n",
      "Distribution of assistant tokens:\n",
      "   min / max: 13, 30\n",
      "   mean / median: 17.6, 15.5\n",
      "   p5 / p95: 13.0, 21.9\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Processing file: validation_set.jsonl\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Distribution of total tokens:\n",
      "   min / max: 43, 65\n",
      "   mean / median: 51.4, 49.0\n",
      "   p5 / p95: 45.7, 56.9\n",
      "\n",
      "Distribution of assistant tokens:\n",
      "   min / max: 8, 29\n",
      "   mean / median: 15.9, 13.5\n",
      "   p5 / p95: 11.6, 20.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = [training_file_name, validation_file_name]\n",
    "\n",
    "for file in files:\n",
    "    print()\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"Processing file: {file}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "\n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48bf2f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([48, 49, 56, 49, 65, 46, 56, 54, 48, 43],\n",
       " [13, 13, 19, 13, 29, 12, 18, 20, 14, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens, assistant_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb19ba6",
   "metadata": {},
   "source": [
    "## Running the fine tuning model job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31cd1602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-96b976a2e932436b901b1bfcb801cafe\n",
      "Validation file ID: file-cd45f4da179b4f07b5c55dc23d6d00b9\n"
     ]
    }
   ],
   "source": [
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"),\n",
    "    purpose=\"fine-tune\",\n",
    "    user_provided_filename=training_file_name,\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "\n",
    "\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_file_name, \"rb\"),\n",
    "    purpose=\"fine-tune\",\n",
    "    user_provided_filename=validation_file_name,\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650c2d8",
   "metadata": {},
   "source": [
    "# Fine tuning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bd8636",
   "metadata": {},
   "source": [
    "**babbage-002** and **davinci-002** are not trained to follow instructions. Querying these base models should only be done as a point of reference to a fine-tuned version to evaluate the progress of your training.\n",
    "\n",
    "**gpt-35-turbo-0613** - fine-tuning of this model is limited to a subset of regions, and is not available in every region the base model is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11fe8fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftmodel = \"gpt-35-turbo-0613\" # note by He Zhang: has to be exactly this name, not the deployment name.\n",
    "#ftmodel = \"gpt-35-turbo-16k\" # this does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba5231cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-46e808787e8e47d38bd5a85741b394cc\n",
      "Status: pending\n",
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 2\n",
      "  },\n",
      "  \"status\": \"pending\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"training_file\": \"file-96b976a2e932436b901b1bfcb801cafe\",\n",
      "  \"validation_file\": \"file-cd45f4da179b4f07b5c55dc23d6d00b9\",\n",
      "  \"id\": \"ftjob-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"created_at\": 1702523504,\n",
      "  \"updated_at\": 1702523504,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=ftmodel,\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "print(\"Job ID:\", response[\"id\"])\n",
    "print(\"Status:\", response[\"status\"])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9939d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_training_status():\n",
    "    \"\"\"\n",
    "    Check fine tuning process\n",
    "    \"\"\"\n",
    "    response = openai.FineTuningJob.retrieve(job_id)\n",
    "\n",
    "    if response[\"status\"] == \"pending\":\n",
    "        print(f\"Fine tuning of {ftmodel} is PENDING - Please wait\")\n",
    "\n",
    "    elif response[\"status\"] == \"running\":\n",
    "        print(\"\\033[1;31;34m\")\n",
    "        print(f\"Fine tuning of {ftmodel} is RUNNING - Please wait\")\n",
    "\n",
    "    elif response[\"status\"] == \"succeeded\":\n",
    "        print(\"\\033[1;31;32m\")\n",
    "        print(f\"Fine tuning of {ftmodel} is DONE!\")\n",
    "\n",
    "    else:\n",
    "        print(response)\n",
    "\n",
    "    print(\"\\nJob ID:\", job_id)\n",
    "    print(\"Created:\", datetime.datetime.utcfromtimestamp(response[\"created_at\"]))\n",
    "    print(\"Updated:\", datetime.datetime.utcfromtimestamp(response[\"updated_at\"]))\n",
    "\n",
    "    print(\"\\033[0m\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c7ed489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34m\n",
      "Fine tuning of gpt-35-turbo-0613 is RUNNING - Please wait\n",
      "\n",
      "Job ID: ftjob-46e808787e8e47d38bd5a85741b394cc\n",
      "Created: 2023-12-14 03:11:44\n",
      "Updated: 2023-12-14 03:13:17\n",
      "\u001b[0m\n",
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 2\n",
      "  },\n",
      "  \"status\": \"running\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"training_file\": \"file-96b976a2e932436b901b1bfcb801cafe\",\n",
      "  \"validation_file\": \"file-cd45f4da179b4f07b5c55dc23d6d00b9\",\n",
      "  \"id\": \"ftjob-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"created_at\": 1702523504,\n",
      "  \"updated_at\": 1702523597,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "check_training_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f76b0fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;32m\n",
      "Fine tuning of gpt-35-turbo-0613 is DONE!\n",
      "\n",
      "Job ID: ftjob-46e808787e8e47d38bd5a85741b394cc\n",
      "Created: 2023-12-14 03:11:44\n",
      "Updated: 2023-12-14 03:40:52\n",
      "\u001b[0m\n",
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 2\n",
      "  },\n",
      "  \"status\": \"succeeded\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"training_file\": \"file-96b976a2e932436b901b1bfcb801cafe\",\n",
      "  \"validation_file\": \"file-cd45f4da179b4f07b5c55dc23d6d00b9\",\n",
      "  \"result_files\": [\n",
      "    \"file-36cdaed7bcec4702bbfdbff099b82914\"\n",
      "  ],\n",
      "  \"finished_at\": 1702525252,\n",
      "  \"trained_tokens\": 1042,\n",
      "  \"id\": \"ftjob-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"created_at\": 1702523504,\n",
      "  \"updated_at\": 1702525252,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "check_training_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c053c7",
   "metadata": {},
   "source": [
    "> https://oai.azure.com/portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "244ea49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f3c40b24f40> JSON: {\n",
       "  \"has_more\": false,\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 2\n",
       "      },\n",
       "      \"status\": \"succeeded\",\n",
       "      \"model\": \"gpt-35-turbo-0613\",\n",
       "      \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc\",\n",
       "      \"training_file\": \"file-96b976a2e932436b901b1bfcb801cafe\",\n",
       "      \"validation_file\": \"file-cd45f4da179b4f07b5c55dc23d6d00b9\",\n",
       "      \"result_files\": [\n",
       "        \"file-36cdaed7bcec4702bbfdbff099b82914\"\n",
       "      ],\n",
       "      \"finished_at\": 1702525252,\n",
       "      \"trained_tokens\": 1042,\n",
       "      \"id\": \"ftjob-46e808787e8e47d38bd5a85741b394cc\",\n",
       "      \"created_at\": 1702523504,\n",
       "      \"updated_at\": 1702525252,\n",
       "      \"object\": \"fine_tuning.job\"\n",
       "    },\n",
       "    {\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 2\n",
       "      },\n",
       "      \"suffix\": \"gpt-35-turbo-ft-aoai-dashboard\",\n",
       "      \"status\": \"succeeded\",\n",
       "      \"model\": \"gpt-35-turbo-0613\",\n",
       "      \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-88836731c3a1455eb5c153ab06ce6ea0-gpt-35-turbo-ft-aoai-dashboard\",\n",
       "      \"training_file\": \"file-7fa55e97620d4914a62f4e8985cb8367\",\n",
       "      \"validation_file\": \"file-c38b2eb080f941aca3b0860f20bbcfe5\",\n",
       "      \"result_files\": [\n",
       "        \"file-59441162f06845bbb6feda9594927c5c\"\n",
       "      ],\n",
       "      \"finished_at\": 1702381948,\n",
       "      \"trained_tokens\": 1336,\n",
       "      \"id\": \"ftjob-88836731c3a1455eb5c153ab06ce6ea0\",\n",
       "      \"created_at\": 1702378606,\n",
       "      \"updated_at\": 1702381948,\n",
       "      \"object\": \"fine_tuning.job\"\n",
       "    }\n",
       "  ],\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f931d",
   "metadata": {},
   "source": [
    "<img src=\"capture_hezhang.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0afdc9a",
   "metadata": {},
   "source": [
    "## Deploying the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3fa0df",
   "metadata": {},
   "source": [
    "- token:\tThere are multiple ways to generate an authorization token. The easiest method for initial testing is to launch the Cloud Shell from the Azure portal. Then run az account get-access-token. You can use this token as your temporary authorization token for API testing. We recommend storing this in a new environment variable\n",
    "- subscription:\tThe subscription ID for the associated Azure OpenAI resource\n",
    "- resource_group:\tThe resource group name for your Azure OpenAI resource\n",
    "- resource_name:\tThe Azure OpenAI resource name\n",
    "- model_deployment_name:\tThe custom name for your new fine-tuned model deployment. This is the name that will be referenced in your code when making chat completion calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "635694c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": 2\n",
      "  },\n",
      "  \"status\": \"succeeded\",\n",
      "  \"model\": \"gpt-35-turbo-0613\",\n",
      "  \"fine_tuned_model\": \"gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"training_file\": \"file-96b976a2e932436b901b1bfcb801cafe\",\n",
      "  \"validation_file\": \"file-cd45f4da179b4f07b5c55dc23d6d00b9\",\n",
      "  \"result_files\": [\n",
      "    \"file-36cdaed7bcec4702bbfdbff099b82914\"\n",
      "  ],\n",
      "  \"finished_at\": 1702525252,\n",
      "  \"trained_tokens\": 1042,\n",
      "  \"id\": \"ftjob-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"created_at\": 1702523504,\n",
      "  \"updated_at\": 1702525252,\n",
      "  \"object\": \"fine_tuning.job\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "\n",
    "print(response)\n",
    "fine_tuned_model = response[\"fine_tuned_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57b46218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token = os.getenv(\"TOKEN\")\n",
    "token = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IlQxU3QtZExUdnlXUmd4Ql82NzZ1OGtyWFMtSSIsImtpZCI6IlQxU3QtZExUdnlXUmd4Ql82NzZ1OGtyWFMtSSJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuY29yZS53aW5kb3dzLm5ldC8iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC8xNmIzYzAxMy1kMzAwLTQ2OGQtYWM2NC03ZWRhMDgyMGI2ZDMvIiwiaWF0IjoxNzAyNTI4MDg3LCJuYmYiOjE3MDI1MjgwODcsImV4cCI6MTcwMjUzMjk0OCwiYWNyIjoiMSIsImFpbyI6IkFXUUFtLzhWQUFBQTlZeTBTalQ4N0dZUjh0eHRPNGYxanVFVVl3aFdZMGg2a0E2MW41eGYxbEg0bGlRTXJoT3BLbk1MaDFkdFZOTnR4N1E1czZZTzFmNmV4RTl1YmhhNXU4TmwwVmp1elZiSTg4NTBZd1BGMHAxQ0IzWkV2SE0zR1RVV0ZxYlJMbzl1IiwiYWx0c2VjaWQiOiI1OjoxMDAzMjAwMTdDQjUyQTM2IiwiYW1yIjpbInJzYSIsIm1mYSJdLCJhcHBpZCI6ImI2NzdjMjkwLWNmNGItNGE4ZS1hNjBlLTkxYmE2NTBhNGFiZSIsImFwcGlkYWNyIjoiMCIsImRldmljZWlkIjoiNmYwMjdjMDMtYjBiOC00MWMwLTkyNGQtN2NjZjRhOWYxYWVjIiwiZW1haWwiOiJ6aGFuZ2hlQG1pY3Jvc29mdC5jb20iLCJmYW1pbHlfbmFtZSI6IlpoYW5nIiwiZ2l2ZW5fbmFtZSI6IkhlIiwiZ3JvdXBzIjpbImIxMzA0MDIyLTA4ZTYtNDQ3ZC1iMDk0LTE1MzcwNTk3YzZiNiIsIjA5M2I4YTIyLTg0OWYtNGUyYi1iM2M3LTc1YmZlMzA1MDU0NiIsImQzNGM0ZWJlLTQ5ODQtNDkwMy1hNjRkLThjMjAyODNkNTE2YiIsImUzMDk2ZGY3LWI2NWMtNGUzMi1hYjFhLTdhMzVkYzY4NGYwYSJdLCJpZHAiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC83MmY5ODhiZi04NmYxLTQxYWYtOTFhYi0yZDdjZDAxMWRiNDcvIiwiaWR0eXAiOiJ1c2VyIiwiaXBhZGRyIjoiMjQwNDpmODAxOjkwMDA6MWE6ZWZlYTo6MzRmIiwibmFtZSI6IkhlIFpoYW5nIiwib2lkIjoiMGY2NTM4NTItOGVlMS00YTAzLWI2NTMtMTUzYzdjYjQ5MDEzIiwicHVpZCI6IjEwMDMyMDAyNjQ1QTExQjkiLCJyaCI6IjAuQVVZQUU4Q3pGZ0RUalVhc1pIN2FDQ0MyMDBaSWYza0F1dGRQdWtQYXdmajJNQk84QU1RLiIsInNjcCI6InVzZXJfaW1wZXJzb25hdGlvbiIsInN1YiI6Ilp5a2ZTMlEwQlJDakJtU2VwUU9pdElJRnFMQUJ6SDQtOFBOWVpnOFVFd1UiLCJ0aWQiOiIxNmIzYzAxMy1kMzAwLTQ2OGQtYWM2NC03ZWRhMDgyMGI2ZDMiLCJ1bmlxdWVfbmFtZSI6InpoYW5naGVAbWljcm9zb2Z0LmNvbSIsInV0aSI6ImJQZTROVnVyUkV1eDROLW52OFVLQVEiLCJ2ZXIiOiIxLjAiLCJ3aWRzIjpbImI3OWZiZjRkLTNlZjktNDY4OS04MTQzLTc2YjE5NGU4NTUwOSJdLCJ4bXNfY2FlIjoiMSIsInhtc190Y2R0IjoxNjQ1MTM3MjI4fQ.PmGW5Iv9LuUVg_a0BhWoOGTxEpM-nVNTEr46KcN5bvQQi19cjtQjP3-dHDzYcaZcNSZUnuRHrltq_hW5gFxPTzHKiYQtq2_VtcIGdjaUMJSuheBVz1PYQPtPowFsmQt7uMoStHnSQFOGkgjBNplWPt1hgCOx5NE3f8qU2mrgye4dJgE3TvgEWfa2JrPEjgCH_-TioFqhvUsdV0F50oxLusSuqbi2eK1MDZI8pqmRYTTAWxLHQSP5RUUNGT2AB-0ASJxhXOSs9kYqN2NYnkuSOEqNM57R53Z8nduWAoWeRHcTX_TScjfpyn6Z2nKBQnOq2y4F2C9YU7lWpBqrKnVH0Q\"\n",
    "subscription = os.getenv(\"SUBSCRIPTION\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\")\n",
    "resource_name = os.getenv(\"RESOURCE_NAME\")\n",
    "\n",
    "model_deployment_name = \"gpt-35-turbo-ft-aoai-sdk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc77b4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://management.azure.com/subscriptions/02243ba5-b777-47c6-9ecf-830b204b7593/resourceGroups/OpenAI/providers/Microsoft.CognitiveServices/accounts/explore-openai-sweden-central/deployments/gpt-35-turbo-ft-aoai-sdk\n"
     ]
    }
   ],
   "source": [
    "deploy_params = {\"api-version\": \"2023-05-01\"} # \"2023-07-01-preview\"\n",
    "deploy_headers = {\n",
    "    \"Authorization\": \"Bearer {}\".format(token),\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 10},\n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc\",  # retrieve this value from the previous call\n",
    "            \"version\": \"1\",\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "request_url = f\"https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}\"\n",
    "print(request_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3f00c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"sku\": {\"name\": \"standard\", \"capacity\": 10}, \"properties\": {\"model\": {\"format\": \"OpenAI\", \"name\": \"gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc\", \"version\": \"1\"}}}'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e21936f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new deployment...\n",
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating a new deployment...\")\n",
    "resp = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ace0504e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/02243ba5-b777-47c6-9ecf-830b204b7593/resourceGroups/OpenAI/providers/Microsoft.CognitiveServices/accounts/explore-openai-sweden-central/deployments/gpt-35-turbo-ft-aoai-sdk',\n",
       " 'type': 'Microsoft.CognitiveServices/accounts/deployments',\n",
       " 'name': 'gpt-35-turbo-ft-aoai-sdk',\n",
       " 'sku': {'name': 'standard', 'capacity': 10},\n",
       " 'properties': {'model': {'format': 'OpenAI',\n",
       "   'name': 'gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc',\n",
       "   'version': '1'},\n",
       "  'versionUpgradeOption': 'NoAutoUpgrade',\n",
       "  'capabilities': {'chatCompletion': 'true'},\n",
       "  'provisioningState': 'Creating',\n",
       "  'rateLimits': [{'key': 'request', 'renewalPeriod': 10, 'count': 10},\n",
       "   {'key': 'token', 'renewalPeriod': 60, 'count': 10000}]},\n",
       " 'systemData': {'createdBy': 'zhanghe@microsoft.com',\n",
       "  'createdByType': 'User',\n",
       "  'createdAt': '2023-12-14T04:43:04.3841227Z',\n",
       "  'lastModifiedBy': 'zhanghe@microsoft.com',\n",
       "  'lastModifiedByType': 'User',\n",
       "  'lastModifiedAt': '2023-12-14T04:43:04.3841227Z'},\n",
       " 'etag': '\"e73b827e-75f7-43fc-b687-a89f2a171938\"'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17baedf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created\n"
     ]
    }
   ],
   "source": [
    "print(resp.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3b382612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-35-turbo-ft-aoai-sdk'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel = resp.json()[\"name\"]\n",
    "mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "828f5d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-12-14T04:43:04.3841227Z'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()[\"systemData\"][\"createdAt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "042216db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'format': 'OpenAI',\n",
       " 'name': 'gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc',\n",
       " 'version': '1'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()[\"properties\"][\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c0c5751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployment status of model 'gpt-35-turbo-ft-aoai-sdk': Creating\n"
     ]
    }
   ],
   "source": [
    "status = resp.json()[\"properties\"][\"provisioningState\"]\n",
    "\n",
    "print(f\"Model deployment status of model '{mymodel}': {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b40285f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployment status of model 'gpt-35-turbo-ft-aoai-sdk': Succeeded\n"
     ]
    }
   ],
   "source": [
    "resp = requests.put(\n",
    "    request_url, params=deploy_params, headers=deploy_headers, data=deploy_data\n",
    ")\n",
    "\n",
    "status = resp.json()[\"properties\"][\"provisioningState\"]\n",
    "print(f\"Model deployment status of model '{mymodel}': {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9941add",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf67a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_version = \"2023-05-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7cdd9603",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    engine=mymodel, \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"My name is He.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Hey He, how can I help you?\"},\n",
    "        {\"role\": \"user\", \"content\": \"1+1=?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"2\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"ok, my name again?\"}\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "073cef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8VY9tzOYbJIWNk74YbetfTeZY515P\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1702530165,\n",
      "  \"model\": \"gpt-35-turbo-0613.ft-46e808787e8e47d38bd5a85741b394cc\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Your name is He.\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 58,\n",
      "    \"completion_tokens\": 5,\n",
      "    \"total_tokens\": 63\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "55a477a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer type:\n",
      "\n",
      " <class 'openai.openai_object.OpenAIObject'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer type:\\n\\n\", type(response.choices[0].message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "77c27e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is He.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32957893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c8042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
