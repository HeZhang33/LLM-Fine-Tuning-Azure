{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ad5da8",
   "metadata": {},
   "source": [
    "## Supervised Fine-Tuning GPT-4o Model for text Q&A - An Azure Python SDK Experience\n",
    "\n",
    "Learn how to fine-tune the <code>gpt-4o-2024-08-06</code> model using Python Programming Language - An SDK / Low-Code Experience. This notebook is based on the MS Learn tutorial [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Cbash).\n",
    "\n",
    "He Zhang, Jul. 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a270ee2",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "* Learn the [what, why, and when to use fine-tuning.](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/fine-tuning-considerations)\n",
    "* An Azure subscription.\n",
    "* Access to Azure OpenAI Service.\n",
    "* An Azure OpenAI resource created in the supported fine-tuning region (e.g. Sweden Central).\n",
    "* A deployment of <code>gpt-4o</code> base model, with its deployment name as \"gpt-4o\" for simplicity. \n",
    "* Prepare Training and Validation datasets:\n",
    "  * at least 50 high-quality samples (preferably 1,000s) are required.\n",
    "  * must be formatted in the JSON Lines (JSONL) document with UTF-8 encoding.\n",
    "  * for this test notebook, we use only 10 samples for the demo purpose. \n",
    "* Python version at least: <code>3.10</code>\n",
    "* Python libraries: <code>os, requests, python-dotenv, matplotlib, azure.identity, pandas, openai</code>\n",
    "* The OpenAI Python library version for this test notebook: <code>1.x</code> \n",
    "* [Jupyter Notebooks](https://jupyter.org/)\n",
    "* An `azure.env` file to store your AOAI-related credentials as environmental variables. **Be sure not to share this file with others or upload it to a public GitHub repository.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f837b",
   "metadata": {},
   "source": [
    "### Step 1: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd759f8f",
   "metadata": {},
   "source": [
    "#### Retrieve the Azure OpenAI API key and endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a4647",
   "metadata": {},
   "source": [
    "Go to your Azure OpenAI resource in the Azure portal. The Endpoint and Keys can be found in the **Resource Management: Keys and Endpoint** sub-section.\n",
    "\n",
    "Alternatively, you can also find the same Keys and Endpoint in the **Azure AI Foundry - Azure OpenAI** resource landing page.\n",
    "\n",
    "<img src=\"../../images/screenshot-aoai-keys-and-endpoint.png\" alt=\"Screenshot of the Azure OpenAI resource management pane.\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f3b044",
   "metadata": {},
   "source": [
    "#### Configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd153223",
   "metadata": {},
   "source": [
    "Copy the <code>Endpoint</code> and access <code>KEY</code> (you can use either <code>KEY 1</code> or <code>KEY 2</code>), and paste them accordingly to the variables in the file <code>azure.env</code>. \n",
    "\n",
    "Save the file and close it. \n",
    "\n",
    "**Do not** distribute this file as this contains credential information! \n",
    "\n",
    "<img src=\"../../images/screenshot-azure-env-file.png\" alt=\"Screenshot of the azure.env file that contains credential information - do not show it to others!\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4574dc",
   "metadata": {},
   "source": [
    "#### Install required Python libraries (if not done yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c156fe0-0d1a-4855-a904-bf170f999b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q openai matplotlib pandas json requests tiktoken python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d703e",
   "metadata": {},
   "source": [
    "#### Import required Python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229febe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO, StringIO\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbebe593",
   "metadata": {},
   "source": [
    "#### Load Azure OpenAI credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b7a343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load credential file\n",
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "# Assign Azure resources  \n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\") # name of the Azure Subscription ID\n",
    "resource_name = os.getenv(\"RESOURCE_NAME\") # name of the AOAI resource\n",
    "rg_name = os.getenv(\"RG_NAME\") # name of the resource group\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "  api_version = \"2024-10-21\"  # This API version or later is required to access seed/events/checkpoint features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750df8e2-e82c-4e66-834b-2768a0fd1e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test AOAI connection\n",
    "completion = client.chat.completions.create(  \n",
    "    model=\"gpt-4o\",  \n",
    "    messages=[{\"role\":\"user\", \"content\":\"hello\"}],  \n",
    "    max_tokens=500,  \n",
    "    temperature=0.7)\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9fd9ad-2e97-4916-839e-6c197c613b21",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175f7ee-9197-461f-adfd-c7786433d409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_jsonl(file_path, top_lines=5):\n",
    "    \"\"\"Reads and displays the first few lines from a .jsonl (JSON Lines) file.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        messages = [line for line in f]\n",
    "        for mes in messages[:top_lines]:\n",
    "            print(mes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e05c1a-da86-4f8c-ba48-49d022a30766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_ft_metrics(results_df, window_size=5):\n",
    "    \"\"\"Plot fine-tuning metrics including loss and accuracy for training and validation.\"\"\"\n",
    "    # Drop rows where valid_loss is NaN or valid_loss is -1.0\n",
    "    filtered_df = results_df.dropna(subset=['valid_loss'])\n",
    "    filtered_df = filtered_df.loc[filtered_df['valid_loss'] != -1.0]\n",
    "    # Compute rolling means\n",
    "    results_df_smooth = results_df.rolling(window=window_size).mean()\n",
    "    filtered_df_smooth = filtered_df.rolling(window=window_size).mean()\n",
    "    # Plot the curves\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(results_df_smooth['step'], results_df_smooth['train_loss'],  color='blue')\n",
    "    plt.title('Train Loss')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(results_df_smooth['step'], results_df_smooth['train_mean_token_accuracy'], color='green')\n",
    "    plt.title('Train Mean Token Accuracy')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Accuracy')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(filtered_df_smooth['step'], filtered_df_smooth['valid_loss'], color='red')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(filtered_df_smooth['step'], filtered_df_smooth['valid_mean_token_accuracy'], color='orange')\n",
    "    plt.title('Validation Mean Token Accuracy')\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74534675-e708-4e5c-b96d-8b4d712f41b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def date_sorted_df(details_dict):\n",
    "    \"\"\"Create a pandas DataFrame from a dictionary and sort it by a 'created' or 'created_at' timestamp column for displaying OpenAI API tables.\"\"\"\n",
    "    df = pd.DataFrame(details_dict)\n",
    "    \n",
    "    if 'created' in df.columns:\n",
    "        df.rename(columns={'created': 'created_at'}, inplace=True)\n",
    "    \n",
    "    # Convert 'created_at' from Unix timestamp to human-readable date/time format\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'], unit='s').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    if 'finished_at' in df.columns:\n",
    "        # Convert 'finished_at' from Unix timestamp to human-readable date/time format, keeping null values as is\n",
    "        df['finished_at'] = pd.to_datetime(df['finished_at'], unit='s', errors='coerce').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # Sort DataFrame by 'created_at' in descending order\n",
    "    df = df.sort_values(by='created_at', ascending=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfdf556",
   "metadata": {},
   "source": [
    "### Step 2: Prepare Training & Validation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bed57b",
   "metadata": {},
   "source": [
    "#### The training and validation datasets have been made ready for you. \n",
    "\n",
    "For illustration purposes, each dataset contains only 10 samples, and each sample consists of a single-turn Q&A pair.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e4e564",
   "metadata": {},
   "source": [
    "<code>training_set_10samples.jsonl</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72662b27",
   "metadata": {},
   "source": [
    "```yaml\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, \n",
    "     {\"role\": \"user\", \"content\": \"Who discovered Antarctica?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}]}\n",
    "\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "     {\"role\": \"user\", \"content\": \"What is the biggest ocean?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"The Pacific Ocean. It's not like it's a small pond or anything.\"}]}\n",
    "\n",
    "{\"messages\": ...}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3b290",
   "metadata": {},
   "source": [
    "<code>validation_set_10samples.jsonl</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ff181",
   "metadata": {},
   "source": [
    "```yaml\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, \n",
    "     {\"role\": \"user\", \"content\": \"What's the capital of Australia?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"It's Canberra, not Sydney. Shocking, I know!\"}]}\n",
    "\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Who wrote 'The Great Gatsby'?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"Some guy named F. Scott Fitzgerald. Ever heard of him?\"}]}\n",
    "     \n",
    "{\"messages\": ...}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b30e0",
   "metadata": {},
   "source": [
    "#### Do initial data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd7abd3-016a-4c8a-839c-ee609ee65ff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check some data samples \n",
    "training_file_path = \"./training_set_10samples.jsonl\"\n",
    "validation_file_path = \"./validation_set_10samples.jsonl\" \n",
    "\n",
    "read_jsonl(training_file_path, top_lines=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c83d3",
   "metadata": {},
   "source": [
    "### Step 3: Upload Datasets for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54a4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload the training dataset\n",
    "training_response = client.files.create(\n",
    "    file = open(training_file_path, \"rb\"), \n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "# Upload the validation dataset\n",
    "validation_response = client.files.create(\n",
    "    file = open(validation_file_path, \"rb\"), \n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aee27a",
   "metadata": {},
   "source": [
    "### Step 4: Configure and Start Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927f0c4",
   "metadata": {},
   "source": [
    "Now you can submit your fine-tuning training job. \n",
    "\n",
    "The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "You can use the job ID to monitor the status of the fine-tuning job. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b19c984-3f86-4e52-bdca-f24cff356fe8",
   "metadata": {},
   "source": [
    "Here is some guidance if you want to adjust the hyperparameters of the fine-tuning process. You can keep them as `None` to use default values. \n",
    "\n",
    "| Hyperparameter                       | Description                                                                                                                                                                              |\n",
    "|-----------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| `Beta` | \"auto\" or number, is a new option that is only available for DPO fine-tuning. It's a floating point number between 0 and 2 that controls how strictly the new model will adhere to its previous behavior, versus aligning with the provided preferences. A high number will be more conservative (favoring previous behavior), and a lower number will be more aggressive (favor the newly provided preferences more often). |\n",
    "| `Batch size` | The batch size to use for training. When set to default, batch_size is calculated as 0.2% of examples in training set and the max is 256. |\n",
    "| `Learning rate multiplier` | The fine-tuning learning rate is the original learning rate used for pre-training multiplied by this multiplier. We recommend experimenting with values between 0.5 and 2. Empirically, we've found that larger learning rates often perform better with larger batch sizes. Must be between 0.0 and 5.0. |\n",
    "| `Number of epochs` | Number of training epochs. An epoch refers to one full cycle through the data set. If set to default, number of epochs will be determined dynamically based on the input data. |\n",
    "| `Seed` | The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases. If a seed is not specified, one will be generated for you. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22877387",
   "metadata": {},
   "source": [
    "In this example we're also passing the seed parameter. The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but can differ in rare cases. If a seed isn't specified, one will be generated for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798accfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submit the fine-tuning training job\n",
    "project_name = \"gpt4o-text-ft-10-samples-qa\"\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    suffix=project_name,\n",
    "    training_file = training_file_id,\n",
    "    validation_file = validation_file_id,\n",
    "    model = \"gpt-4o-2024-08-06\", \n",
    "    seed = 105 # seed parameter that controls reproducibility of the fine-tuning job.\n",
    ")\n",
    "\n",
    "# monitor the status\n",
    "job_id = response.id\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa608e2f",
   "metadata": {},
   "source": [
    "### Step 5: Track Fine-Tuning Job Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5ad52",
   "metadata": {},
   "source": [
    "#### Track the training job status\n",
    "\n",
    "Note that the training will take around 50 to 90 mins for the provided datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd130026-dc06-4066-b3a7-5e161a5fe4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the fine-tuning job status\n",
    "client.fine_tuning.jobs.list(limit=1).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aae34d",
   "metadata": {},
   "source": [
    "#### List fine-tuning events\n",
    "\n",
    "API version: 2024-05-01-preview or later is required for this command.\n",
    "\n",
    "While not necessary to complete fine-tuning it can be helpful to examine the individual fine-tuning events that were generated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5507ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List 5 recent fine-tuning jobs\n",
    "ft_jobs = client.fine_tuning.jobs.list(limit=5).to_dict()\n",
    "display(date_sorted_df(pd.DataFrame(ft_jobs['data'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a39a6-7bd5-4761-9b92-42bb14012c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the name of your newly text fine-tuned model\n",
    "ft_job = client.fine_tuning.jobs.retrieve(\"ftjob-8071d8e2e7294603b26585c19a9a0757\") # replace \"ftjob-0a4c...\" with the actual job-id in your list\n",
    "fine_tuned_model = ft_job.to_dict()['fine_tuned_model']\n",
    "fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb97418a-e5e9-496d-8a09-bfcbb4dbdf7a",
   "metadata": {},
   "source": [
    "#### Retrieve fine-tuning metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff10d85-1d93-4265-b209-047a6517b583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve fine-tuning metrics from result file\n",
    "result_file_id = ft_job.to_dict()['result_files'][0]\n",
    "results_content = client.files.content(result_file_id).content.decode()\n",
    "\n",
    "data_io = StringIO(results_content)\n",
    "results_df = pd.read_csv(data_io)\n",
    "display(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417267e1-7c71-4bc9-ba81-32c609b99214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot train and validation metrics\n",
    "show_ft_metrics(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a58b85",
   "metadata": {},
   "source": [
    "### Step 6: Deploy The Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370097d4",
   "metadata": {},
   "source": [
    "__Note__: Only one deployment is permitted for a customized model. An error occurs if you select an already-deployed customized model.  \n",
    "\n",
    "The code below shows how to deploy the model using the Control Plane API. Take a look at the [Azure OpenAI fine-tuning documentation](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo&pivots=programming-language-python#deploy-fine-tuned-model) for more details.\n",
    "\n",
    "The deployment process may take 10 to 20 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3848e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy the fine-tuned model as an Azure Managed Online Endpoint\n",
    "aoai_deployment_name = project_name # AOAI deployment name. Use as model parameter for inferencing\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "token = credential.get_token(\"https://management.azure.com/.default\").token\n",
    "\n",
    "deploy_params = {'api-version': \"2023-05-01\"} \n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 50}, \n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": fine_tuned_model, # retrieve this value from the previous calls, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription_id}/resourceGroups/{rg_name}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{aoai_deployment_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe6e0b",
   "metadata": {},
   "source": [
    "### Step 7: Test the Deployed Fine-Tuned Model¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e5bbc",
   "metadata": {},
   "source": [
    "After your fine-tuned model is deployed, you can use it like any other deployed model in either the [Chat Playground in Azure AI Foundry](https://ai.azure.com/), or via the chat completion API. \n",
    "\n",
    "For example, you can send a chat completion call to your deployed model, as shown in the following Python code snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4cef4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check output from the deployed supervised fine-tuned model via AOAI API\n",
    "response = client.chat.completions.create(\n",
    "    model = aoai_deployment_name, # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How do you think Paris?\"}\n",
    "    ],\n",
    "    temperature=0.7, \n",
    "    max_tokens=800)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65563bf0",
   "metadata": {},
   "source": [
    "### Step 8: Delete The Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb666e8",
   "metadata": {},
   "source": [
    "It is **strongly recommended** that once you're done with this tutorial and have tested a few chat completion calls against your fine-tuned model, that you delete the model deployment, since the fine-tuned / customized models have an [hourly hosting cost](https://azure.microsoft.com/zh-cn/pricing/details/cognitive-services/openai-service/#pricing) associated with them once they are deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8326f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d238055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
