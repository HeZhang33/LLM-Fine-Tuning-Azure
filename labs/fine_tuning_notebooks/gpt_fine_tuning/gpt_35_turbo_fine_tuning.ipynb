{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ad5da8",
   "metadata": {},
   "source": [
    "## Fine-Tuning GPT-3.5 Model - A Python SDK Experience\n",
    "\n",
    "Learn how to fine-tune the <code>gpt-35-turbo-0613</code> model using Python Programming Language - An SDK / Code Experience. This notebook is based on the MS Learn tutorial [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/tutorials/fine-tune?tabs=python%2Cbash).\n",
    "\n",
    "He Zhang, Feb. 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a270ee2",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "* Learn the [what, why, and when to use fine-tuning.](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/fine-tuning-considerations)\n",
    "* An Azure subscription.\n",
    "* Access to Azure OpenAI Service.\n",
    "* An Azure OpenAI resource created in the supported fine-tuning region (e.g. Sweden Central).\n",
    "* Prepare Training and Validation datasets:\n",
    "  * at least 50 high-quality samples (preferably 1,000s) are required.\n",
    "  * must be formatted in the JSON Lines (JSONL) document with UTF-8 encoding.\n",
    "  * for this test notebook, we use only 10 samples for the demo purpose. \n",
    "* Python version at least: <code>3.7.1</code>\n",
    "* Python libraries: <code>json, requests, os, tiktoken, time, python-dotenv, numpy, openai</code>\n",
    "* The OpenAI Python library version for this test notebook: <code>0.28.1</code>\n",
    "* [Jupyter Notebooks](https://jupyter.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f837b",
   "metadata": {},
   "source": [
    "### Step 1: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd759f8f",
   "metadata": {},
   "source": [
    "#### Retrieve the Azure OpenAI API key and endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a4647",
   "metadata": {},
   "source": [
    "Go to your resource in the Azure portal. The Endpoint and Keys can be found in the Resource Management section Go to your resource in the Azure portal.  \n",
    "<img src=\"../../images/screenshot-aoai-keys-and-endpoint.png\" alt=\"Screenshot of the Azure OpenAI resource management pane.\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f3b044",
   "metadata": {},
   "source": [
    "#### Configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd153223",
   "metadata": {},
   "source": [
    "Copy the <code>Endpoint</code> and access <code>KEY</code> (you can use either <code>KEY 1</code> or <code>KEY 2</code>), and paste them accordingly to the variables in the file <code>azure.env</code>. Save the file and close it. **Do not** distribute this file as this contains credential information! \n",
    "<img src=\"../../images/screenshot-azure-env-file.png\" alt=\"Screenshot of the azure.env file that contains credential information - do not show it to others!\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4574dc",
   "metadata": {},
   "source": [
    "#### Install required Python libraries (if not done yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"openai==0.28.1\" json requests os tiktoken time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d703e",
   "metadata": {},
   "source": [
    "#### Import required Python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229febe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "import requests\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbebe593",
   "metadata": {},
   "source": [
    "#### Load Azure OpenAI credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b7a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = \"2023-12-01-preview\" # This API version or later is required to access fine-tuning for turbo/babbage-002/davinci-002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfdf556",
   "metadata": {},
   "source": [
    "### Step 2: Prepare Training & Validation Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bed57b",
   "metadata": {},
   "source": [
    "#### The training and validation datasets have been made ready for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e4e564",
   "metadata": {},
   "source": [
    "<code>training_set.jsonl</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72662b27",
   "metadata": {},
   "source": [
    "```yaml\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, \n",
    "     {\"role\": \"user\", \"content\": \"Who discovered Antarctica?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"Some chaps named Fabian Gottlieb von Bellingshausen and Mikhail Lazarev, as if they don't teach that in every school!\"}]}\n",
    "\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "     {\"role\": \"user\", \"content\": \"What is the biggest ocean?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"The Pacific Ocean. It's not like it's a small pond or anything.\"}]}\n",
    "\n",
    "{\"messages\": ...}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e3b290",
   "metadata": {},
   "source": [
    "<code>validation_set.jsonl</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ff181",
   "metadata": {},
   "source": [
    "```yaml\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"}, \n",
    "     {\"role\": \"user\", \"content\": \"What's the capital of Australia?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"It's Canberra, not Sydney. Shocking, I know!\"}]}\n",
    "\n",
    "{\"messages\": \n",
    "    [{\"role\": \"system\", \"content\": \"Clippy is a factual chatbot that is also sarcastic.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Who wrote 'The Great Gatsby'?\"}, \n",
    "     {\"role\": \"assistant\", \"content\": \"Some guy named F. Scott Fitzgerald. Ever heard of him?\"}]}\n",
    "     \n",
    "{\"messages\": ...}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19b30e0",
   "metadata": {},
   "source": [
    "#### Do initial checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set\n",
    "with open(\"training_set.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    training_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Training dataset stats\n",
    "print(\"Number of examples in training set:\", len(training_dataset))\n",
    "print(\"First example in training set:\")\n",
    "for message in training_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007634ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation set\n",
    "with open(\"validation_set.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    validation_dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Validation dataset stats\n",
    "print(\"\\nNumber of examples in validation set:\", len(validation_dataset))\n",
    "print(\"First example in validation set:\")\n",
    "for message in validation_dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9f529",
   "metadata": {},
   "source": [
    "#### Examine the token numbers\n",
    "Now you can then run some additional code from OpenAI using the tiktoken library to validate the token counts. Individual examples need to remain under the <code>gpt-35-turbo-0613</code> model's input token limit of <code>4,096</code> tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\") # default encoding used by gpt-4, turbo, and text-embedding-ada-002 models\n",
    "\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
    "\n",
    "files = ['training_set.jsonl', 'validation_set.jsonl']\n",
    "\n",
    "for file in files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "\n",
    "    total_tokens = []\n",
    "    assistant_tokens = []\n",
    "\n",
    "    for ex in dataset:\n",
    "        messages = ex.get(\"messages\", {})\n",
    "        total_tokens.append(num_tokens_from_messages(messages))\n",
    "        assistant_tokens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "    print_distribution(total_tokens, \"total tokens\")\n",
    "    print_distribution(assistant_tokens, \"assistant tokens\")\n",
    "    print('*' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c83d3",
   "metadata": {},
   "source": [
    "### Step 3: Upload Datasets for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "training_file_name = \"training_set.jsonl\"\n",
    "validation_file_name = \"validation_set.jsonl\"\n",
    "\n",
    "training_response = openai.File.create(\n",
    "    file=open(training_file_name, \"rb\"), \n",
    "    purpose=\"fine-tune\", \n",
    "    user_provided_filename=training_file_name\n",
    ")\n",
    "training_file_id = training_response[\"id\"]\n",
    "\n",
    "validation_response = openai.File.create(\n",
    "    file=open(validation_file_name, \"rb\"), \n",
    "    purpose=\"fine-tune\", \n",
    "    user_provided_filename=validation_file_name\n",
    ")\n",
    "validation_file_id = validation_response[\"id\"]\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aee27a",
   "metadata": {},
   "source": [
    "### Step 4: Begin Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a927f0c4",
   "metadata": {},
   "source": [
    "Now you can submit your fine-tuning training job. \n",
    "\n",
    "The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "You can use the job ID to monitor the status of the fine-tuning job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.FineTuningJob.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-35-turbo-0613\", # must be exactly this name\n",
    ")\n",
    "\n",
    "job_id = response[\"id\"]\n",
    "\n",
    "print(\"Job ID:\", response[\"id\"])\n",
    "print(\"Status:\", response[\"status\"])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa608e2f",
   "metadata": {},
   "source": [
    "### Step 5: Track Fine-Tuning Job Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5ad52",
   "metadata": {},
   "source": [
    "You can track the training job status by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa4b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track fine-tuning job training status\n",
    "start_time = time.time()\n",
    "\n",
    "# Get the status of our fine-tuning job.\n",
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "\n",
    "status = response[\"status\"]\n",
    "\n",
    "# If the job isn't done yet, poll it every 10 seconds.\n",
    "while status not in [\"succeeded\", \"failed\"]:\n",
    "    time.sleep(10)\n",
    "    \n",
    "    response = openai.FineTuningJob.retrieve(job_id)\n",
    "    print(response)\n",
    "    print(\"Elapsed time: {} minutes {} seconds\".format(int((time.time() - start_time) // 60), int((time.time() - start_time) % 60)))\n",
    "    status = response[\"status\"]\n",
    "    print(f\"Status: {status}\")\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print(f\"Fine-tuning job {job_id} finished with status: {status}\")\n",
    "\n",
    "# List all fine-tuning jobs for this resource.\n",
    "print(\"Checking other fine-tune jobs for this resource.\")\n",
    "response = openai.FineTuningJob.list()\n",
    "print(f'Found {len(response[\"data\"])} fine-tune jobs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afeb619",
   "metadata": {},
   "source": [
    "To get the full results, you can run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve fine_tuned_model name\n",
    "response = openai.FineTuningJob.retrieve(job_id)\n",
    "print(response)\n",
    "\n",
    "fine_tuned_model = response[\"fine_tuned_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a58b85",
   "metadata": {},
   "source": [
    "### Step 6: Deploy The Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370097d4",
   "metadata": {},
   "source": [
    "Model deployment must be done using the [REST API](https://learn.microsoft.com/en-us/rest/api/cognitiveservices/accountmanagement/deployments/create-or-update?view=rest-cognitiveservices-accountmanagement-2023-05-01&tabs=HTTP), which requires separate authorization, a different API path, and a different API version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53296c51",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>variable</th>\n",
    "<th>Definition</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>token</td>\n",
    "<td>There are multiple ways to generate an authorization token. The easiest method for initial testing is to launch the Cloud Shell from the <a href=\"https://portal.azure.com\" data-linktype=\"external\">Azure portal</a>. Then run <a href=\"/en-us/cli/azure/account#az-account-get-access-token()\" data-linktype=\"absolute-path\"><code>az account get-access-token</code></a>. You can use this token as your temporary authorization token for API testing. We recommend storing this in a new environment variable</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>subscription</td>\n",
    "<td>The subscription ID for the associated Azure OpenAI resource</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>resource_group</td>\n",
    "<td>The resource group name for your Azure OpenAI resource</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>resource_name</td>\n",
    "<td>The Azure OpenAI resource name</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>model_deployment_name</td>\n",
    "<td>The custom name for your new fine-tuned model deployment. This is the name that will be referenced in your code when making chat completion calls.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fine_tuned_model</td>\n",
    "<td>Retrieve this value from your fine-tuning job results in the previous step. It will look like <code>gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83</code>. You will need to add that value to the deploy_data json.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3848e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "token= os.getenv(\"TEMP_AUTH_TOKEN\") \n",
    "subscription = \"<YOUR_SUBSCRIPTION_ID>\"  \n",
    "resource_group = \"<YOUR_RESOURCE_GROUP_NAME>\"\n",
    "resource_name = \"<YOUR_AZURE_OPENAI_RESOURCE_NAME>\"\n",
    "model_deployment_name =\"YOUR_CUSTOM_MODEL_DEPLOYMENT_NAME\" \n",
    "\n",
    "deploy_params = {\"api-version\": \"2023-05-01\"} \n",
    "deploy_headers = {\"Authorization\": \"Bearer {}\".format(token), \"Content-Type\": \"application/json\"}\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1}, \n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"<YOUR_FINE_TUNED_MODEL>\", #retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "print(\"Creating a new deployment...\")\n",
    "request_url = f\"https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}\"\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404f0a0",
   "metadata": {},
   "source": [
    "You can check on your deployment progress in the Azure OpenAI Studio:\n",
    "\n",
    "<img src=\"../../images/screenshot-deployed-fine-tuned-model-via-sdk.png\" alt=\"Screenshot of the Azure OpenAI Studio - showing the model deployment status.\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefe6e0b",
   "metadata": {},
   "source": [
    "### Step 7: Test And Use The Deployed Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e5bbc",
   "metadata": {},
   "source": [
    "After your fine-tuned model is deployed, you can use it like any other deployed model in either the [Chat Playground of Azure OpenAI Studio](https://oai.azure.com/), or via the chat completion API. \n",
    "\n",
    "For example, you can send a chat completion call to your deployed model, as shown in the following Python code snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4cef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\") \n",
    "openai.api_version = \"2023-05-15\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    engine=\"gpt-35-turbo-ft\", # engine = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Does Azure OpenAI support customer managed keys?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, customer managed keys are supported by Azure OpenAI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Do other Azure AI services support this too?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65563bf0",
   "metadata": {},
   "source": [
    "### Step 8: Delete The Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb666e8",
   "metadata": {},
   "source": [
    "It is **strongly recommended** that once you're done with this tutorial and have tested a few chat completion calls against your fine-tuned model, that you delete the model deployment, since the fine-tuned / customized models have an [hourly hosting cost](https://azure.microsoft.com/zh-cn/pricing/details/cognitive-services/openai-service/#pricing) associated with them once they are deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c328ad63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8326f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
